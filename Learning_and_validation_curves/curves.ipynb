{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "           id diagnosis  mean_radius  mean_texture  mean_perimeter  mean_area  \\\n0      842302         M        17.99         10.38          122.80     1001.0   \n1      842517         M        20.57         17.77          132.90     1326.0   \n2    84300903         M        19.69         21.25          130.00     1203.0   \n3    84348301         M        11.42         20.38           77.58      386.1   \n4    84358402         M        20.29         14.34          135.10     1297.0   \n..        ...       ...          ...           ...             ...        ...   \n564    926424         M        21.56         22.39          142.00     1479.0   \n565    926682         M        20.13         28.25          131.20     1261.0   \n566    926954         M        16.60         28.08          108.30      858.1   \n567    927241         M        20.60         29.33          140.10     1265.0   \n568     92751         B         7.76         24.54           47.92      181.0   \n\n     mean_smoothness  mean_compactness  mean_concavity  mean_concave_points  \\\n0            0.11840           0.27760         0.30010              0.14710   \n1            0.08474           0.07864         0.08690              0.07017   \n2            0.10960           0.15990         0.19740              0.12790   \n3            0.14250           0.28390         0.24140              0.10520   \n4            0.10030           0.13280         0.19800              0.10430   \n..               ...               ...             ...                  ...   \n564          0.11100           0.11590         0.24390              0.13890   \n565          0.09780           0.10340         0.14400              0.09791   \n566          0.08455           0.10230         0.09251              0.05302   \n567          0.11780           0.27700         0.35140              0.15200   \n568          0.05263           0.04362         0.00000              0.00000   \n\n     ...  worst_radius  worst_texture  worst_perimeter  worst_area  \\\n0    ...        25.380          17.33           184.60      2019.0   \n1    ...        24.990          23.41           158.80      1956.0   \n2    ...        23.570          25.53           152.50      1709.0   \n3    ...        14.910          26.50            98.87       567.7   \n4    ...        22.540          16.67           152.20      1575.0   \n..   ...           ...            ...              ...         ...   \n564  ...        25.450          26.40           166.10      2027.0   \n565  ...        23.690          38.25           155.00      1731.0   \n566  ...        18.980          34.12           126.70      1124.0   \n567  ...        25.740          39.42           184.60      1821.0   \n568  ...         9.456          30.37            59.16       268.6   \n\n     worst_smoothness  worst_compactness  worst_concavity  \\\n0             0.16220            0.66560           0.7119   \n1             0.12380            0.18660           0.2416   \n2             0.14440            0.42450           0.4504   \n3             0.20980            0.86630           0.6869   \n4             0.13740            0.20500           0.4000   \n..                ...                ...              ...   \n564           0.14100            0.21130           0.4107   \n565           0.11660            0.19220           0.3215   \n566           0.11390            0.30940           0.3403   \n567           0.16500            0.86810           0.9387   \n568           0.08996            0.06444           0.0000   \n\n     worst_concave_points  worst_symmetry  worst_fractal_dimension  \n0                  0.2654          0.4601                  0.11890  \n1                  0.1860          0.2750                  0.08902  \n2                  0.2430          0.3613                  0.08758  \n3                  0.2575          0.6638                  0.17300  \n4                  0.1625          0.2364                  0.07678  \n..                    ...             ...                      ...  \n564                0.2216          0.2060                  0.07115  \n565                0.1628          0.2572                  0.06637  \n566                0.1418          0.2218                  0.07820  \n567                0.2650          0.4087                  0.12400  \n568                0.0000          0.2871                  0.07039  \n\n[569 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>mean_radius</th>\n      <th>mean_texture</th>\n      <th>mean_perimeter</th>\n      <th>mean_area</th>\n      <th>mean_smoothness</th>\n      <th>mean_compactness</th>\n      <th>mean_concavity</th>\n      <th>mean_concave_points</th>\n      <th>...</th>\n      <th>worst_radius</th>\n      <th>worst_texture</th>\n      <th>worst_perimeter</th>\n      <th>worst_area</th>\n      <th>worst_smoothness</th>\n      <th>worst_compactness</th>\n      <th>worst_concavity</th>\n      <th>worst_concave_points</th>\n      <th>worst_symmetry</th>\n      <th>worst_fractal_dimension</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>25.380</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.16220</td>\n      <td>0.66560</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>24.990</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.12380</td>\n      <td>0.18660</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>23.570</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.14440</td>\n      <td>0.42450</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>14.910</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.20980</td>\n      <td>0.86630</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>22.540</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.13740</td>\n      <td>0.20500</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>926424</td>\n      <td>M</td>\n      <td>21.56</td>\n      <td>22.39</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>0.11100</td>\n      <td>0.11590</td>\n      <td>0.24390</td>\n      <td>0.13890</td>\n      <td>...</td>\n      <td>25.450</td>\n      <td>26.40</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n      <td>0.14100</td>\n      <td>0.21130</td>\n      <td>0.4107</td>\n      <td>0.2216</td>\n      <td>0.2060</td>\n      <td>0.07115</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>926682</td>\n      <td>M</td>\n      <td>20.13</td>\n      <td>28.25</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>0.09780</td>\n      <td>0.10340</td>\n      <td>0.14400</td>\n      <td>0.09791</td>\n      <td>...</td>\n      <td>23.690</td>\n      <td>38.25</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n      <td>0.11660</td>\n      <td>0.19220</td>\n      <td>0.3215</td>\n      <td>0.1628</td>\n      <td>0.2572</td>\n      <td>0.06637</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>926954</td>\n      <td>M</td>\n      <td>16.60</td>\n      <td>28.08</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>0.08455</td>\n      <td>0.10230</td>\n      <td>0.09251</td>\n      <td>0.05302</td>\n      <td>...</td>\n      <td>18.980</td>\n      <td>34.12</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n      <td>0.11390</td>\n      <td>0.30940</td>\n      <td>0.3403</td>\n      <td>0.1418</td>\n      <td>0.2218</td>\n      <td>0.07820</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>927241</td>\n      <td>M</td>\n      <td>20.60</td>\n      <td>29.33</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.11780</td>\n      <td>0.27700</td>\n      <td>0.35140</td>\n      <td>0.15200</td>\n      <td>...</td>\n      <td>25.740</td>\n      <td>39.42</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.16500</td>\n      <td>0.86810</td>\n      <td>0.9387</td>\n      <td>0.2650</td>\n      <td>0.4087</td>\n      <td>0.12400</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>92751</td>\n      <td>B</td>\n      <td>7.76</td>\n      <td>24.54</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>0.05263</td>\n      <td>0.04362</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>9.456</td>\n      <td>30.37</td>\n      <td>59.16</td>\n      <td>268.6</td>\n      <td>0.08996</td>\n      <td>0.06444</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2871</td>\n      <td>0.07039</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows × 32 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'\n",
    "column_names = ['id', 'diagnosis', 'mean_radius', 'mean_texture', 'mean_perimeter',\n",
    "                'mean_area', 'mean_smoothness', 'mean_compactness', 'mean_concavity',\n",
    "                'mean_concave_points', 'mean_symmetry', 'mean_fractal_dimension',\n",
    "                'se_radius', 'se_texture', 'se_perimeter', 'se_area', 'se_smoothness',\n",
    "                'se_compactness', 'se_concavity', 'se_concave_points', 'se_symmetry',\n",
    "                'se_fractal_dimension', 'worst_radius', 'worst_texture', 'worst_perimeter',\n",
    "                'worst_area', 'worst_smoothness', 'worst_compactness', 'worst_concavity',\n",
    "                'worst_concave_points', 'worst_symmetry', 'worst_fractal_dimension']\n",
    "df = pd.read_csv(url, header=None, names=column_names)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['B', 'M'], dtype=object)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df.iloc[:, 2:]\n",
    "y = df.iloc[:, 1]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "le.classes_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9473684210526315"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, not cross-validations is performed, only a single pipeline.\n",
    "# The estimator should be the last argument in make_pipeline()\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                        LinearDiscriminantAnalysis(n_components=1), # n_components must be <= min(n_features, n_classes-1)\n",
    "                        LogisticRegression(penalty='l2', max_iter=10000, n_jobs=-1),\n",
    "                        )\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "accuracy = pipe_lr.score(X_test, y_test)\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr,\n",
    "                                                        X=X_train,\n",
    "                                                        y=y_train,\n",
    "                                                        train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                                                        cv=10,\n",
    "                                                        n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.        , 1.        , 1.        , 1.        , 1.        ,\n        1.        , 1.        , 1.        , 1.        , 1.        ],\n       [0.98765432, 0.98765432, 1.        , 1.        , 1.        ,\n        1.        , 1.        , 1.        , 1.        , 1.        ],\n       [0.98360656, 0.99180328, 0.98360656, 0.98360656, 0.98360656,\n        0.98360656, 0.98360656, 0.98360656, 0.98360656, 0.98360656],\n       [0.96932515, 0.98159509, 0.98159509, 0.98159509, 0.97546012,\n        0.97546012, 0.97546012, 0.97546012, 0.97546012, 0.97546012],\n       [0.98529412, 0.9754902 , 0.98529412, 0.99019608, 0.98039216,\n        0.98039216, 0.98039216, 0.98039216, 0.98039216, 0.98039216],\n       [0.9877551 , 0.97959184, 0.98367347, 0.99183673, 0.9755102 ,\n        0.97959184, 0.97959184, 0.97959184, 0.97959184, 0.97959184],\n       [0.98251748, 0.98251748, 0.98251748, 0.98601399, 0.97902098,\n        0.97552448, 0.97902098, 0.98251748, 0.98251748, 0.98251748],\n       [0.98470948, 0.98776758, 0.98165138, 0.98470948, 0.97859327,\n        0.98165138, 0.98165138, 0.97553517, 0.98165138, 0.98165138],\n       [0.98369565, 0.98097826, 0.97826087, 0.98097826, 0.98097826,\n        0.98097826, 0.98097826, 0.97826087, 0.98097826, 0.98369565],\n       [0.9804401 , 0.98288509, 0.97555012, 0.97799511, 0.97555012,\n        0.97799511, 0.97799511, 0.97799511, 0.9804401 , 0.9804401 ]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores\n",
    "# rows: number of train samples\n",
    "# columns: number of folds (cv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std  = np.std(train_scores,  axis=1)\n",
    "\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std  = np.std(test_scores,  axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(train_sizes, train_mean,\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean,\n",
    "         color='green', linestyle='--',\n",
    "         marker='s', markersize=5,\n",
    "         label='Validation (test) accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training examples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.03])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "train_scores, test_scores = validation_curve(estimator=pipe_lr,\n",
    "                                             X=X_train,\n",
    "                                             y=y_train,\n",
    "                                             param_name='logisticregression__C',\n",
    "                                             param_range=param_range,\n",
    "                                             cv=10,\n",
    "                                             )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std  = np.std(train_scores,  axis=1)\n",
    "test_mean  = np.mean(test_scores,  axis=1)\n",
    "test_std   = np.std(test_scores,   axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(param_range, train_mean,\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "plt.fill_between(param_range,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std, alpha=0.15,\n",
    "                 color='blue')\n",
    "\n",
    "plt.plot(param_range, test_mean,\n",
    "         color='green', linestyle='--',\n",
    "         marker='s', markersize=5,\n",
    "         label='Validation (test) accuracy')\n",
    "\n",
    "plt.fill_between(param_range,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Parameter C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.8, 1.03])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# the key difference between learning and validation curves is that the learning curve analyzes model performance with respect to training data size, while the validation curve analyzes model performance with respect to hyperparameters tunning of the estimator/transformer."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}